import streamlit as st
import pandas as pd
import numpy as np
import spacy
import matplotlib.pyplot as plt
import networkx as nx
from sklearn.cluster import KMeans
from sklearn.feature_extraction.text import TfidfVectorizer
from transformers import pipeline
import time
import json
from collections import defaultdict

# åˆå§‹åŒ–æ¨¡å‹
nlp = spacy.load("zh_core_web_sm")
sentiment_analyzer = pipeline("sentiment-analysis", model="uer/roberta-base-finetuned-jd-full-chinese")
ner_model = pipeline("ner", model="dslim/bert-base-NER")

# é¢„å®šä¹‰çŠ¯ç½ªå…³é”®è¯åº“
CRIME_KEYWORDS = {
    "æ¯’å“": ["ç™½ç²‰", "å†°", "å¶å­", "ç³–", "è´§", "ä¸œè¥¿", "å¿«é€’", "å†°å¦¹", "æºœå†°", "é£è¡Œ", "é£è¡Œå‘˜", "é£å¶å­", "é£è¡Œå‘˜",
             "ä¸œè¥¿"],
    "è¯ˆéª—": ["è½¬è´¦", "æ±‡æ¬¾", "é“¶è¡Œå¡", "å¯†ç ", "éªŒè¯ç ", "ä¸­å¥–", "ä¿è¯é‡‘", "æ‰‹ç»­è´¹", "è¿”åˆ©", "åˆ·å•", "æŠ•èµ„", "å½©ç¥¨",
             "èµŒåš"],
    "æš´åŠ›": ["ç ", "æ€", "æ‰“", "æ•™è®­", "æ”¶æ‹¾", "åºŸäº†", "åšäº†", "å¹²æ‰", "æŠ¥ä»‡", "ç®—è´¦", "è§è¡€", "å·¥å…·"],
    "èµŒåš": ["èµŒ", "ç‰Œ", "å±€", "åº„", "ä¸‹æ³¨", "æ¢­å“ˆ", "ç™¾å®¶ä¹", "é¾™è™", "èµŒèµ„", "æŠ½æ°´", "æ´—ç ", "ç›˜å£"],
    "èµ°ç§": ["è´§", "è¿‡å…³", "æ°´è·¯", "ä¸Šå²¸", "æ¸…å…³", "æŠ¥å…³", "é›†è£…ç®±", "ç å¤´", "æ¸”èˆ¹", "å¿«è‰‡", "è¾¹å¢ƒ", "é€šé“"],
}

# é¢„å®šä¹‰çŠ¯ç½ªæš—è¯­æ˜ å°„
EUPHEMISMS = {
    "èŒ¶å¶": "æ¯’å“",
    "é’“é±¼": "èµ°ç§",
    "å¿«é€’": "æ¯’å“äº¤æ˜“",
    "æµ·é²œ": "èµ°ç§è´§ç‰©",
    "ç³–": "å†°æ¯’",
    "ä¸œè¥¿": "æ¯’å“",
    "è´§": "æ¯’å“",
    "æ”¶ç§Ÿ": "æ”¶èµŒå€º",
    "çœ‹æµ·": "èµ°ç§äº¤æ˜“",
    "å¼€å¼ ": "çŠ¯ç½ªæ´»åŠ¨å¼€å§‹",
    "è€åœ°æ–¹": "çŠ¯ç½ªäº¤æ˜“åœ°ç‚¹"
}


# åˆå§‹åŒ–æ•°æ®
def load_sample_data():
    return [
        "é¾™å“¥ï¼šä»Šæ™šè€åœ°æ–¹äº¤è´§ï¼Œå¸¦å¤Ÿç°é‡‘",
        "å¼ ä¸‰ï¼šæ˜ç™½ï¼Œè¿™æ¬¡è´§çš„å“è´¨å¦‚ä½•ï¼Ÿ",
        "æå››ï¼šå¤©æ°”è½¬å‡‰äº†ï¼Œå¤šç©¿ç‚¹",
        "ç‹äº”ï¼šç›®æ ‡ä¸Šé’©äº†ï¼Œå·²è½¬è´¦5ä¸‡",
        "é¾™å“¥ï¼šæ”¶åˆ°ï¼Œåˆ†ä½ ä¸‰æˆ",
        "å¼ ä¸‰ï¼šä¸Šæ¬¡çš„'ç³–'çº¯åº¦ä¸å¤Ÿï¼Œå®¢æˆ·ä¸æ»¡æ„",
        "æå››ï¼šæ–°'å¿«é€’'æ˜å¤©åˆ°ï¼Œæ³¨æ„æŸ¥æ”¶",
        "ç‹äº”ï¼šè¿™æ¬¡å¿…é¡»å¹²ç¥¨å¤§çš„",
        "è·¯äººç”²ï¼šå‘¨æœ«ä¸€èµ·åƒé¥­å—ï¼Ÿ",
        "é¾™å“¥ï¼šä¸å®ˆè§„çŸ©çš„äººè¦å¥½å¥½æ•™è®­",
        "å¼ ä¸‰ï¼šè­¦å¯Ÿæœ€è¿‘æŸ¥å¾—ä¸¥ï¼Œå°å¿ƒç‚¹",
        "æå››ï¼šæƒ³ç»“æŸè¿™ç§ç”Ÿæ´»...",
        "ç‹äº”ï¼šæµ·è¾¹é’“é±¼è®¡åˆ’å–æ¶ˆï¼Œæ”¹ä¸‹å‘¨",
    ]


# å®ä½“è¯†åˆ«
def extract_entities(text):
    doc = nlp(text)
    entities = []
    for ent in doc.ents:
        if ent.label_ in ["PERSON", "ORG", "GPE"]:
            entities.append((ent.text, ent.label_))
    return entities


# æ•æ„Ÿè¯é¢˜åˆ†æ
def detect_sensitive_topics(text):
    topics = []
    for topic, keywords in CRIME_KEYWORDS.items():
        if any(keyword in text for keyword in keywords):
            topics.append(topic)
    return topics


# çŠ¯ç½ªæ„å›¾åˆ†æ
def analyze_criminal_intent(text):
    # æš—è¯­æ£€æµ‹
    for euphemism, meaning in EUPHEMISMS.items():
        if euphemism in text:
            return f"çŠ¯ç½ªæš—è¯­æ£€æµ‹: [{euphemism}] = {meaning}", 85

    # å…³é”®è¯åŒ¹é…
    for topic, keywords in CRIME_KEYWORDS.items():
        if any(keyword in text for keyword in keywords):
            return f"å…³é”®è¯è§¦å‘: {topic}", 90

    # æƒ…æ„Ÿå¢å¼ºåˆ†æ
    sentiment = sentiment_analyzer(text)[0]
    if sentiment['label'] == 'NEGATIVE' and sentiment['score'] > 0.9:
        return "é«˜è´Ÿé¢æƒ…ç»ª: " + text, 75

    return "æœªæ£€æµ‹åˆ°æ˜æ˜¾æ„å›¾", 5


# æƒ…æ„Ÿåˆ†æ
def analyze_sentiment(text):
    result = sentiment_analyzer(text)[0]
    return result['label'], result['score']


# æ„å»ºå…³ç³»å›¾è°±
def build_relationship_graph(messages):
    G = nx.DiGraph()
    entity_messages = defaultdict(list)

    # ç¬¬ä¸€éï¼šæ”¶é›†æ‰€æœ‰å®ä½“
    for msg in messages:
        entities = extract_entities(msg)
        for entity, label in entities:
            G.add_node(entity, type=label)

    # ç¬¬äºŒéï¼šå»ºç«‹å®ä½“å…³ç³»
    for i, msg in enumerate(messages):
        entities = [e[0] for e in extract_entities(msg)]
        for j in range(len(entities)):
            for k in range(j + 1, len(entities)):
                if G.has_edge(entities[j], entities[k]):
                    G[entities[j]][entities[k]]['weight'] += 1
                else:
                    G.add_edge(entities[j], entities[k], weight=1)
                entity_messages[(entities[j], entities[k])].append(msg)

    return G, entity_messages


# èšç±»åˆ†æ
def cluster_messages(messages, n_clusters=4):
    vectorizer = TfidfVectorizer()
    X = vectorizer.fit_transform(messages)
    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(X)

    clusters = {}
    for i, label in enumerate(kmeans.labels_):
        if label not in clusters:
            clusters[label] = []
        clusters[label].append(messages[i])

    return clusters


# ä¸»åº”ç”¨
def main():
    st.set_page_config(page_title="AIæ…§çœ¼ï¼šæ¶‰æ¡ˆæ–‡æœ¬æ™ºèƒ½åˆ†æç³»ç»Ÿ", layout="wide")
    st.title("ğŸ•µï¸â€â™‚ï¸ AIæ…§çœ¼ï¼šæ¶‰æ¡ˆæ–‡æœ¬æ™ºèƒ½åˆ†æä¸é¢„è­¦ç³»ç»Ÿ")
    st.caption("åŸºäºæ·±åº¦å­¦ä¹ çš„å¤šç»´åº¦çŠ¯ç½ªæ„å›¾è¯†åˆ«å¹³å° | å¸æ³•æŠ€æœ¯èµ›é¡¹è§£å†³æ–¹æ¡ˆ")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'messages' not in st.session_state:
        st.session_state.messages = load_sample_data()

    # ä¾§è¾¹æ æ§åˆ¶é¢æ¿
    with st.sidebar:
        st.header("ç³»ç»Ÿæ§åˆ¶é¢æ¿")
        analysis_type = st.selectbox("åˆ†ææ¨¡å¼", ["å®æ—¶åˆ†æ", "æ‰¹é‡å¤„ç†"])
        risk_threshold = st.slider("é£é™©é¢„è­¦é˜ˆå€¼", 0, 100, 70)
        st.divider()

        st.subheader("æ•°æ®ç®¡ç†")
        if st.button("åŠ è½½ç¤ºä¾‹æ•°æ®"):
            st.session_state.messages = load_sample_data()
            st.success("ç¤ºä¾‹æ•°æ®å·²åŠ è½½!")

        uploaded_file = st.file_uploader("ä¸Šä¼ èŠå¤©è®°å½•", type=["txt", "csv"])
        if uploaded_file:
            if uploaded_file.type == "text/plain":
                st.session_state.messages = uploaded_file.read().decode("utf-8").splitlines()
            st.success(f"å·²åŠ è½½ {len(st.session_state.messages)} æ¡è®°å½•")

        st.divider()
        st.subheader("ç³»ç»Ÿä¿¡æ¯")
        st.info("""
        **æ ¸å¿ƒåŠŸèƒ½æ¶æ„**:
        - å…³é”®å®ä½“è¯†åˆ«
        - æ•æ„Ÿè¯é¢˜èšç±»
        - æ„å›¾é£é™©è¯„åˆ†
        - æƒ…æ„Ÿå€¾å‘åˆ†æ
        """)

    # ä¸»ç•Œé¢
    tab1, tab2, tab3, tab4 = st.tabs(["å®æ—¶åˆ†æ", "å…³ç³»å›¾è°±", "èšç±»åˆ†æ", "é¢„è­¦æŠ¥å‘Š"])

    with tab1:
        st.subheader("å®æ—¶æ–‡æœ¬åˆ†æ")
        input_text = st.text_input("è¾“å…¥æ–‡æœ¬è¿›è¡Œåˆ†æ", "ä»Šæ™šè€åœ°æ–¹äº¤è´§ï¼Œå¸¦å¤Ÿç°é‡‘")

        if st.button("åˆ†ææ–‡æœ¬", type="primary"):
            with st.spinner("AIåˆ†æä¸­..."):
                # å®ä½“è¯†åˆ«
                entities = extract_entities(input_text)

                # æ•æ„Ÿè¯é¢˜
                topics = detect_sensitive_topics(input_text)

                # æ„å›¾åˆ†æ
                intent, risk_score = analyze_criminal_intent(input_text)

                # æƒ…æ„Ÿåˆ†æ
                sentiment, sentiment_score = analyze_sentiment(input_text)

                # æ˜¾ç¤ºç»“æœ
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.subheader("ğŸ” å®ä½“è¯†åˆ«")
                    if entities:
                        for entity, label in entities:
                            st.info(f"{entity} ({label})")
                    else:
                        st.warning("æœªè¯†åˆ«åˆ°å®ä½“")

                with col2:
                    st.subheader("ğŸ“Œ æ•æ„Ÿè¯é¢˜")
                    if topics:
                        for topic in topics:
                            st.error(f"âš ï¸ {topic}")
                    else:
                        st.success("æœªæ£€æµ‹åˆ°æ•æ„Ÿè¯é¢˜")

                with col3:
                    st.subheader("ğŸ¯ çŠ¯ç½ªæ„å›¾")
                    progress_color = "red" if risk_score > risk_threshold else "green"
                    st.metric("é£é™©è¯„åˆ†", f"{risk_score}%", delta="é«˜é£é™©" if risk_score > risk_threshold else "ä½é£é™©")
                    st.progress(risk_score / 100, text=f"**{intent}**")

                with col4:
                    st.subheader("ğŸ˜ƒ æƒ…æ„Ÿåˆ†æ")
                    if sentiment == "NEGATIVE":
                        st.error(f"è´Ÿé¢æƒ…ç»ª: {sentiment_score:.0%}")
                        st.markdown("<div style='text-align:center; font-size:50px;'>ğŸ”¥</div>", unsafe_allow_html=True)
                    else:
                        st.success(f"æ­£é¢æƒ…ç»ª: {sentiment_score:.0%}")
                        st.markdown("<div style='text-align:center; font-size:50px;'>ğŸ˜Š</div>", unsafe_allow_html=True)

    with tab2:
        st.subheader("çŠ¯ç½ªç½‘ç»œå…³ç³»å›¾è°±")

        if st.button("ç”Ÿæˆå…³ç³»å›¾è°±", key="graph_btn"):
            with st.spinner("æ„å»ºçŠ¯ç½ªç½‘ç»œ..."):
                G, entity_messages = build_relationship_graph(st.session_state.messages)

                # è®¡ç®—èŠ‚ç‚¹å¤§å°ï¼ˆåŸºäºåº¦æ•°ï¼‰
                node_sizes = [G.degree(n) * 500 for n in G.nodes()]

                # ç»˜åˆ¶å›¾è°±
                plt.figure(figsize=(12, 8))
                pos = nx.spring_layout(G, seed=42)
                nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color="lightcoral", alpha=0.9)
                nx.draw_networkx_edges(G, pos, width=1.0, alpha=0.5, edge_color="gray")
                nx.draw_networkx_labels(G, pos, font_size=12, font_family="SimHei")

                plt.title("çŠ¯ç½ªç½‘ç»œå…³ç³»å›¾è°±", fontsize=16)
                plt.axis("off")
                st.pyplot(plt)

                # æ˜¾ç¤ºèŠ‚ç‚¹è¯¦æƒ…
                selected_node = st.selectbox("é€‰æ‹©èŠ‚ç‚¹æŸ¥çœ‹è¯¦æƒ…", list(G.nodes()))

                if selected_node:
                    st.subheader(f"èŠ‚ç‚¹: {selected_node}")

                    # é‚»å±…èŠ‚ç‚¹
                    neighbors = list(G.neighbors(selected_node))
                    st.write(f"**å…³è”èŠ‚ç‚¹**: {', '.join(neighbors) if neighbors else 'æ— '}")

                    # ç›¸å…³æ¶ˆæ¯
                    related_msgs = []
                    for neighbor in neighbors:
                        if (selected_node, neighbor) in entity_messages:
                            related_msgs.extend(entity_messages[(selected_node, neighbor)])

                    if related_msgs:
                        st.subheader("ç›¸å…³æ¶ˆæ¯")
                        for msg in set(related_msgs):
                            st.caption(f"- {msg}")
                    else:
                        st.info("æœªæ‰¾åˆ°ç›¸å…³æ¶ˆæ¯")

    with tab3:
        st.subheader("æ•æ„Ÿè¯é¢˜èšç±»åˆ†æ")
        n_clusters = st.slider("èšç±»æ•°é‡", 2, 6, 4)

        if st.button("æ‰§è¡Œèšç±»åˆ†æ", key="cluster_btn"):
            with st.spinner("èšç±»åˆ†æä¸­..."):
                clusters = cluster_messages(st.session_state.messages, n_clusters)

                # æ˜¾ç¤ºèšç±»ç»“æœ
                for cluster_id, messages in clusters.items():
                    with st.expander(f"è¯é¢˜èšç±» #{cluster_id + 1} (å…±{len(messages)}æ¡)"):
                        for msg in messages:
                            # é«˜äº®å…³é”®è¯
                            highlighted = msg
                            for keywords in CRIME_KEYWORDS.values():
                                for kw in keywords:
                                    if kw in msg:
                                        highlighted = highlighted.replace(kw,
                                                                          f"<mark style='background-color:yellow'>{kw}</mark>")
                            st.markdown(f"- {highlighted}", unsafe_allow_html=True)

    with tab4:
        st.subheader("çŠ¯ç½ªé¢„è­¦æŠ¥å‘Š")

        if st.button("ç”Ÿæˆé¢„è­¦æŠ¥å‘Š", type="primary", key="report_btn"):
            with st.spinner("åˆ†ææ‰€æœ‰æ¶ˆæ¯å¹¶ç”ŸæˆæŠ¥å‘Š..."):
                # åˆ†ææ‰€æœ‰æ¶ˆæ¯
                high_risk = []
                entities_count = defaultdict(int)
                topic_count = defaultdict(int)

                for msg in st.session_state.messages:
                    _, risk_score = analyze_criminal_intent(msg)
                    if risk_score > risk_threshold:
                        high_risk.append(msg)

                    # ç»Ÿè®¡å®ä½“
                    for entity, _ in extract_entities(msg):
                        entities_count[entity] += 1

                    # ç»Ÿè®¡è¯é¢˜
                    topics = detect_sensitive_topics(msg)
                    for topic in topics:
                        topic_count[topic] += 1

                # æ˜¾ç¤ºé«˜é£é™©æ¶ˆæ¯
                st.subheader(f"é«˜é£é™©æ¶ˆæ¯ ({len(high_risk)}æ¡)")
                if high_risk:
                    for msg in high_risk:
                        st.error(f"âš ï¸ {msg}")
                else:
                    st.success("æœªæ£€æµ‹åˆ°é«˜é£é™©æ¶ˆæ¯")

                # å®ä½“ç»Ÿè®¡
                st.subheader("å…³é”®å®ä½“ç»Ÿè®¡")
                if entities_count:
                    top_entities = sorted(entities_count.items(), key=lambda x: x[1], reverse=True)[:5]
                    df_entities = pd.DataFrame(top_entities, columns=["å®ä½“", "å‡ºç°æ¬¡æ•°"])
                    st.bar_chart(df_entities.set_index("å®ä½“"))
                else:
                    st.info("æœªè¯†åˆ«åˆ°å…³é”®å®ä½“")

                # è¯é¢˜ç»Ÿè®¡
                st.subheader("æ•æ„Ÿè¯é¢˜åˆ†å¸ƒ")
                if topic_count:
                    fig, ax = plt.subplots()
                    ax.pie(topic_count.values(), labels=topic_count.keys(), autopct="%1.1f%%", startangle=90)
                    ax.axis("equal")
                    st.pyplot(fig)
                else:
                    st.info("æœªæ£€æµ‹åˆ°æ•æ„Ÿè¯é¢˜")

                # ç”ŸæˆæŠ¥å‘Šæ‘˜è¦
                st.divider()
                st.subheader("åˆ†ææŠ¥å‘Šæ‘˜è¦")
                col1, col2 = st.columns(2)

                with col1:
                    st.metric("æ€»æ¶ˆæ¯é‡", len(st.session_state.messages))
                    st.metric("é«˜é£é™©æ¶ˆæ¯", len(high_risk))

                with col2:
                    st.metric("è¯†åˆ«å®ä½“æ•°", len(entities_count))
                    st.metric("æ•æ„Ÿè¯é¢˜ç±»å‹", len(topic_count))

                # é£é™©ç­‰çº§è¯„ä¼°
                risk_percentage = len(high_risk) / len(st.session_state.messages) * 100
                risk_level = "é«˜å±" if risk_percentage > 20 else "ä¸­å±" if risk_percentage > 5 else "ä½å±"
                st.progress(risk_percentage/ 100, text=f"**æ•´ä½“é£é™©ç­‰çº§: {risk_level} ({risk_percentage:.1f}%)**")

if __name__ == "__main__":
    main()